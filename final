import pandas as pd
import os
from urllib.parse import urlparse
from urllib.request import urlopen
from urllib.error import URLError

# Load the Excel file containing hyperlinks
excel_file = 'links.xlsx'  # Replace with the path to your Excel file
df = pd.read_excel(excel_file)

# Create a directory to store the downloaded HTML files (if it doesn't exist)
output_directory = 'downloaded_html'
os.makedirs(output_directory, exist_ok=True)

# Define a function to download HTML from a URL and save it
def download_html_from_link(link, output_dir):
    try:
        parsed_url = urlparse(link)
        scheme = parsed_url.scheme

        if scheme in ('http', 'https', 'ftp'):
            with urlopen(link) as response:
                if response.status == 200:
                    # Extract the filename from the URL
                    filename = os.path.join(output_dir, os.path.basename(parsed_url.path))
                    with open(filename, 'wb') as file:
                        file.write(response.read())
                    print(f"Downloaded and saved {filename}")
                else:
                    print(f"Failed to download {link}. Status code: {response.status}")
        else:
            print(f"Unsupported scheme: {scheme} for {link}")
    except URLError as e:
        print(f"Error downloading {link}: {e}")

# Iterate through the Excel cells with hyperlinks and download HTML
for index, row in df.iterrows():
    hyperlink = row['HyperlinkColumn']  # Replace with your column name
    download_html_from_link(hyperlink, output_directory)

print("HTML files downloaded successfully.")
