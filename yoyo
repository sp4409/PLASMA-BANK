import pandas as pd
import requests
import os
from urllib.parse import urlparse, unquote

# Load the Excel file containing the hyperlinks
excel_file = 'links.xlsx'  # Replace with the path to your Excel file
df = pd.read_excel(excel_file)

# Create a directory to store the downloaded HTML files (if it doesn't exist)
output_directory = 'downloaded_html'
os.makedirs(output_directory, exist_ok=True)

# Define a function to download HTML from a URL and save it with the original hyperlink name
def download_and_rename(link):
    try:
        response = requests.get(link)
        if response.status_code == 200:
            parsed_url = urlparse(link)
            filename = os.path.join(output_directory, unquote(parsed_url.path).split('/')[-1])
            
            with open(filename, 'wb') as file:
                file.write(response.content)
                
            print(f"Downloaded and saved {filename}")
        else:
            print(f"Failed to download {link}. Status code: {response.status_code}")
    except Exception as e:
        print(f"Error downloading {link}: {e}")

# Iterate through the hyperlinks and download HTML, renaming the files
for index, row in df.iterrows():
    hyperlink = row['Hyperlink']  # Assuming your Excel column is named 'Hyperlink'
    download_and_rename(hyperlink)

print("HTML files downloaded and renamed successfully.")
