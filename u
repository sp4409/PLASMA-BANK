import pandas as pd
import requests
from urllib.parse import urlparse
import openpyxl
import os

# Function to download HTML files into a folder
def download_html_file(url, folder_path):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            # Extract the filename from the URL
            file_name = urlparse(url).path.split('/')[-1]
            # Save the HTML content to a file inside the folder
            file_path = os.path.join(folder_path, file_name)
            with open(file_path, 'wb') as file:
                file.write(response.content)
            print(f"Downloaded: {file_name}")
        else:
            print(f"Failed to download: {url}")
    except Exception as e:
        print(f"Error downloading {url}: {str(e)}")

# Replace 'your_excel_file.xlsx' and 'Sheet1' with the actual file and sheet name
excel_file = 'your_excel_file.xlsx'
sheet_name = 'Sheet1'

# Create a folder to store downloaded files
output_folder = 'downloaded_files'
if not os.path.exists(output_folder):
    os.makedirs(output_folder)

# Load the Excel file
df = pd.read_excel(excel_file)

# Assuming the HTML file URLs are in a column named 'URL'
url_column = 'URL'

# Iterate through the URLs in the Excel file, download HTML files into the folder
for index, row in df.iterrows():
    url = row[url_column]
    download_html_file(url, output_folder)
    
    # Get hyperlink address for cell K(index+2)
    cell_address = f'K{index + 2}'
    hyperlink_address = get_hyperlink_address(excel_file, sheet_name, cell_address)
    
    if hyperlink_address:
        print(f"Hyperlink address for cell {cell_address}: {hyperlink_address}")
    else:
        print(f"No hyperlink found in cell {cell_address}.")
